{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_gaussian_process.kernels import ExpQuadKernel\n",
    "from graph_gaussian_process import util\n",
    "from graph_gaussian_process.torch import GraphGaussianProcess\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from tabulate import tabulate\n",
    "import torch as th\n",
    "\n",
    "\n",
    "mpl.rcParams[\"figure.dpi\"] = 144"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering Gaussian processes on directed acyclic graphs is a general approach to reduce the computational burden for inference. However, often, we are interested in graph structures that capture the spatial relationships between nodes. The function `lattice_predecessors` does just that. It constructs a directed graph for nodes on a lattice, ensuring that the graph is acyclic. Two options are supported: Cuboidal and ellipsoidal receptive fields. The latter are preferable because they preserve the isotropy of the space we are trying to approximate. They are also more efficient because the volume of a hyperellipsoid is strictly smaller than a hypercube with the same diameter, reducing the number of nodes in the receptive field. For example, in three dimensions, the relative volume of a sphere and cube is\n",
    "$$\n",
    "\\frac{V_\\mathrm{sphere}}{V_\\mathrm{cube}}=\\frac{4\\pi r^3 / 3}{\\left(2 r\\right)^3}\\approx 0.52.\n",
    "$$\n",
    "The number of nodes is reduced by a factor of two. But, because matrix inversion required to evaluate the likelihood scales approximately cubicly with the number of nodes, we can reduce the computational cost by almost an order of magnitude. \n",
    "\n",
    "The cell below illustrates the receptive fields in two dimensions and shows both predecessors (that the example node depends on in the likelihood) and successors (that depend on the example node). The union of predecessors and successors is the receptive field of the node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the lattice size, receptive field size, and choose example node positions.\n",
    "width, height = 10, 15\n",
    "k = (4, 3)\n",
    "x, y = 5, 7\n",
    "\n",
    "shape = (width, height)\n",
    "node = np.ravel_multi_index((x, y), shape)\n",
    "coords = util.coordgrid(np.arange(width), np.arange(height))\n",
    "\n",
    "# For each of the two receptive field methods, ...\n",
    "fig, axes = plt.subplots(1, 3, sharex=True, sharey=True)\n",
    "for ax, bounds in zip(axes, util.LatticeBounds):\n",
    "    # Plot the lattice and example node.\n",
    "    ax.scatter(*coords.T, color=\"silver\", marker=\".\")\n",
    "    ax.scatter(*coords[node], label=\"example node\", zorder=99).set_edgecolor(\"w\")\n",
    "    \n",
    "    # Get the lattice predecessors and construct a directed graph.\n",
    "    predecessors = util.lattice_predecessors((width, height), k, bounds=bounds)\n",
    "    edge_index = util.predecessors_to_edge_index(predecessors, indexing=\"numpy\")\n",
    "    graph = util.edge_index_to_graph(edge_index)\n",
    "    \n",
    "    # Show predecessors (that the example node depends on in the likelihood) and successors \n",
    "    # (that depend on the example node in the likelihood).\n",
    "    for label in [\"predecessors\", \"successors\"]:\n",
    "        # Get the nodes and ensure they satisfy the ordering constraint.\n",
    "        nodes = np.asarray(list(getattr(graph, label)(node)))\n",
    "        if label == \"predecessors\":\n",
    "            assert (nodes <= node).all()\n",
    "        else:\n",
    "            assert (nodes >= node).all()\n",
    "        \n",
    "        # Plot the nodes.\n",
    "        zorder = 10 if label == \"predecessors\" else 8\n",
    "        ax.scatter(*coords[nodes].T, label=label, zorder=zorder).set_edgecolor(\"w\")\n",
    "        edges = graph.out_edges(node) if label == \"successors\" else graph.in_edges(node)\n",
    "        edges = nx.draw_networkx_edges(graph, coords, edges, ax=ax, node_size=0, alpha=0.5, \n",
    "                                       arrowsize=7)\n",
    "        for edge in edges:\n",
    "            edge.set_zorder(9)\n",
    "            \n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_title(f\"{bounds.value} bounds\")\n",
    "    ax.set_xlabel(\"Coordinate $x_1$\")\n",
    "        \n",
    "axes[0].set_ylabel(\"Coordinate $x_2$\")\n",
    "axes[0].yaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))\n",
    "axes[0].legend(loc=\"upper right\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compare how samples from the true Gaussian process and our nearest-neighbor approximation compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up parameters for a Gaussian process.\n",
    "seed = 0\n",
    "n = 201\n",
    "x = th.linspace(0, 1, n)\n",
    "X = x[:, None]\n",
    "kernel = ExpQuadKernel(1.2, 0.1, 1e-3)\n",
    "ks = [2, 10, 20, 30]\n",
    "\n",
    "# Construct the exact Gaussian process and draw a realization.\n",
    "dist = th.distributions.MultivariateNormal(th.zeros(n), kernel(X))\n",
    "th.manual_seed(seed)\n",
    "y = dist.sample()\n",
    "log_prob_rows = [(\"exact\", dist.log_prob(y))]\n",
    "\n",
    "# Draw realizations from graph Gaussian processes with different sizes.\n",
    "ys = []\n",
    "for k in ks:\n",
    "    predecessors = util.lattice_predecessors(x.shape, k)\n",
    "    gdist = GraphGaussianProcess(dist.loc, X, predecessors, kernel)\n",
    "    th.manual_seed(seed)\n",
    "    ys.append(gdist.sample())\n",
    "    log_prob_rows.append((f\"k = {k}\", gdist.log_prob(y)))\n",
    "\n",
    "# Compare the realizations.\n",
    "fig, ax = plt.subplots()\n",
    "for k, y_ in zip(ks, ys):\n",
    "    ax.plot(x, y_, label=f\"$k={k}$\")\n",
    "ax.plot(x, y, color=\"k\", ls=\"--\", label=\"exact\")\n",
    "ax.set_xlabel(\"Cooordinate $x$\")\n",
    "ax.set_ylabel(\"Function $y(x)$\")\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "\n",
    "# Show the log probabilities under different approximations.\n",
    "print(tabulate(log_prob_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the same idea in two dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "shape = (70, 70)\n",
    "kernel = ExpQuadKernel(1.1, 4, 1e-3)\n",
    "k = 4\n",
    "\n",
    "width, height = shape\n",
    "x = th.arange(width)\n",
    "y = th.arange(height)\n",
    "coords = th.as_tensor(util.coordgrid(x, y))\n",
    "dist = th.distributions.MultivariateNormal(th.zeros(coords.shape[0]), kernel(coords))\n",
    "th.manual_seed(seed)\n",
    "eta = dist.sample()\n",
    "print(f\"reference log_prob = {dist.log_prob(eta)}\")\n",
    "\n",
    "etas = {\n",
    "    \"exact\": eta,\n",
    "}\n",
    "\n",
    "ref = util.num_lattice_predecessors(k, \"cube\", 2)\n",
    "\n",
    "# Add different predecessor shapes.\n",
    "for bounds in util.LatticeBounds:\n",
    "    # Pick the scale that's closest in terms of number of predecessors in the graph.\n",
    "    num_predecessors = util.num_lattice_predecessors(np.arange(10), bounds, 2)\n",
    "    l = np.argmin(np.abs(num_predecessors - ref))\n",
    "    \n",
    "    predecessors = util.lattice_predecessors(shape, l, bounds)\n",
    "    gdist = GraphGaussianProcess(dist.loc, coords, predecessors, kernel)\n",
    "    print(f\"{bounds}: # predecessors = {predecessors.shape[1]}; log_prob = {gdist.log_prob(eta)}\")\n",
    "    th.manual_seed(seed)\n",
    "    etas[bounds.value] = gdist.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, sharex=True, sharey=True)\n",
    "for ax, (label, eta) in zip(axes.ravel(), etas.items()):\n",
    "    ax.pcolormesh(x, y, eta.reshape(shape).T)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_title(label)\n",
    "    \n",
    "    pearsonr, _ = stats.pearsonr(eta, etas['exact'])\n",
    "    print(f\"{label} corr with ground truth: {pearsonr}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "ce292631760a50db98487f107c57a4e83e7303c2c65ea0b6fb35e4138a49650e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
