{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gptools.stan.examples import compile, sample_kwargs_from_env\n",
    "from gptools.stan.examples.poisson_regression import simulate, plot_realization_1d\n",
    "from gptools.util.kernels import ExpQuadKernel\n",
    "from gptools.util import plot_band, lattice_predecessors, predecessors_to_edge_index\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "mpl.rcParams[\"figure.dpi\"] = 144"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider a simple Poisson regression model for count data $y$ with a latent log-rate $\\eta$ subject to a Gaussian process prior. The model is specified by\n",
    "$$\\begin{align}\n",
    "\\eta &\\sim \\text{MultivariateNormal}\\left(\\mu, K\\left(x,\\alpha,\\rho,\\epsilon\\right)\\right)\\\\\n",
    "y & \\sim \\text{Poisson}\\left(\\exp\\eta\\right),\n",
    "\\end{align}$$\n",
    "where $x$ are the observation coordinates. We use a radial basis function kernel $K$ such that\n",
    "$$\n",
    "\\text{cov}\\left(\\eta_i,\\eta_j\\right) = \\alpha^2 \\exp\\left(-\\frac{\\left\\vert x_i-x_j\\right\\vert^2}{2\\rho^2}\\right) + \\epsilon\\delta_{ij},\n",
    "$$\n",
    "where $\\alpha$ is the covariance scale, $\\rho$ is the correlation length, and $\\epsilon$ is a diagonal noise term to ensure the covariance is positive-definite. A realization of the process is shown below. For simplicity, we assume that the kernel parameters are known in this example and use periodic boundary conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the parameters of the model and simulate forwards.\n",
    "np.random.seed(1)\n",
    "num_nodes = 100\n",
    "kernel = ExpQuadKernel(1.2, 5, 1e-3, num_nodes)\n",
    "mu = 1\n",
    "x = np.arange(num_nodes)\n",
    "realization = simulate(x, mu, kernel)\n",
    "plot_realization_1d(realization).legend()\n",
    "\n",
    "predecessors = lattice_predecessors(x.shape, 5)\n",
    "edge_index = predecessors_to_edge_index(predecessors)\n",
    "\n",
    "realization.update({\n",
    "    \"edge_index\": edge_index,\n",
    "    \"num_edges\": edge_index.shape[1],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first fit the model using a centered parametrization, i.e., the parameters of the sampler directly correspond to the latent log-rate $\\eta$. This parametrization is intuitive, but it can be inefficient when the data are not strongly informative. In this example, the information provided by the counts $y$ is relatively low because the mean rate is small. Consequently, $\\eta$ is primarily constrained by the Gaussian process prior such that adjacent points are highly correlated (the data cannot decorrelated them). Posterior samples are thus highly correlated which slows down the sampler. But let's fit this model anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centered_model = compile(\"poisson_regression_centered.stan\")\n",
    "centered_fit = centered_model.sample(realization, **sample_kwargs_from_env())\n",
    "\n",
    "ax = plot_realization_1d(realization)\n",
    "plot_band(x, np.exp(centered_fit.stan_variable(\"eta\")), label=\"inferred rate\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-centered parametrization. \n",
    "\n",
    "The model successfully infers the latent rate. However, in light of the weak data, we consider a non-centered parametrization of the model. In other words, we use a parameter $z\\sim\\text{Normal}\\left(0, 1\\right)$ and transform the white noise to a sample from the Gaussian process. This operation is analogous to sampling from a univariate Gaussian with mean $\\mu$ and scale $\\sigma$ by sampling from a standard Gaussian, multiplying by the scale $\\sigma$, and adding the mean $\\mu$. The two approaches are equivalent but the non-centered parametrization facilitates faster sampling for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_centered_model = compile(\"poisson_regression_non_centered.stan\")\n",
    "non_centered_fit = non_centered_model.sample(realization, **sample_kwargs_from_env())\n",
    "\n",
    "ax = plot_realization_1d(realization)\n",
    "plot_band(x, np.exp(non_centered_fit.stan_variable(\"eta\")), label=\"inferred rate\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling succeeds as before, but the inference is faster because the white noise $z$ is uncorrelated under the prior and the weak data $y$ only induce minimal correlation. Let's consider the tree depth used by the sampler to explore the posterior (larger tree depths correspond to less efficient sampling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for key, fit in [(\"centered\", centered_fit), (\"non_centered\", non_centered_fit)]:\n",
    "    variables = fit.method_variables()\n",
    "    treedepths = np.bincount(variables[\"treedepth__\"].astype(int).ravel())\n",
    "    ax.plot(treedepths, marker='o', label=key)\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Tree depth\")\n",
    "ax.set_ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of samples from the centered parametrization have tree depth greater than six. But all samples from the non-centered parametriazation have tree depth of six or less, explaining the difference in sampling efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourier_model = compile(\"poisson_regression_fourier.stan\", compile=\"force\")\n",
    "fourier_fit = fourier_model.sample(realization, **sample_kwargs_from_env(), sig_figs=9)\n",
    "\n",
    "ax = plot_realization_1d(realization)\n",
    "plot_band(x, np.exp(fourier_fit.stan_variable(\"eta\")), label=\"inferred rate\")\n",
    "ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "ce292631760a50db98487f107c57a4e83e7303c2c65ea0b6fb35e4138a49650e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
